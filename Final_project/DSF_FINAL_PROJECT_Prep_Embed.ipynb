{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The memory_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext memory_profiler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 10:33:27: adding document #0 to Dictionary(0 unique tokens: [])\n",
      "INFO - 10:33:27: built Dictionary(12 unique tokens: ['computer', 'human', 'interface', 'response', 'survey']...) from 9 documents (total 29 corpus positions)\n"
     ]
    }
   ],
   "source": [
    "%config IPCompleter.greedy=True\n",
    "%load_ext memory_profiler\n",
    "%matplotlib inline\n",
    "%run DSF_FINAL_PROJECT_Helper.ipynb\n",
    "%run DSF_FINAL_PROJECT_Helper_General.ipynb\n",
    "%run DSF_FINAL_PROJECT_Plot.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description\n",
    "\n",
    "In this notebook we are going to create and train Word2Vec model (using a dataset from https://ieee-dataport.org/open-access/coronavirus-covid-19-tweets-dataset).\n",
    "\n",
    "With this notebook we will implement the \"transfer learning\" method (https://en.wikipedia.org/wiki/Transfer_learning). So, the Word2Vec model will be the starting point of our unsupervised learning model (since we extract tweets directly without labelling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"background-color:powderblue;\">Twitter Training Dataset Ingestion</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We getting the rated (labelled) dataset from \n",
    "# https://ieee-dataport.org/open-access/coronavirus-covid-19-tweets-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file = pd.read_csv(\"corona_tweets_296.csv\")\n",
    "#df_user = pd.read_csv('corona_tweets_296.csv', index_col='user_id', delimiter='|')\n",
    "df_corona_tweets_train_ori = pd.read_csv('corona_tweets_296.csv', delimiter=',', header=None, names=['tweet_id ', 'rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1347399059334516736</td>\n",
       "      <td>0.136905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1347399059708010496</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1347399059921891328</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id       rate\n",
       "0  1347399059334516736  0.136905\n",
       "1  1347399059708010496  0.000000\n",
       "2  1347399059921891328  0.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_corona_tweets_train_ori.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2975849 entries, 0 to 2975848\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Dtype  \n",
      "---  ------     -----  \n",
      " 0   tweet_id   int64  \n",
      " 1   rate       float64\n",
      "dtypes: float64(1), int64(1)\n",
      "memory usage: 45.4 MB\n"
     ]
    }
   ],
   "source": [
    "df_corona_tweets_train_ori.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corona_tweets_train_filtered = df_corona_tweets_train_ori[df_corona_tweets_train_ori.rate!=0]\n",
    "df_corona_tweets_train_filtered.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corona_tweets_train_filtered = df_corona_tweets_train_filtered[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   tweet_id   1000 non-null   int64  \n",
      " 1   rate       1000 non-null   float64\n",
      "dtypes: float64(1), int64(1)\n",
      "memory usage: 15.8 KB\n"
     ]
    }
   ],
   "source": [
    "df_corona_tweets_train_filtered.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1347399059334516736</td>\n",
       "      <td>0.136905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1347399060219695104</td>\n",
       "      <td>0.098788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1347399060236369922</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id       rate\n",
       "0  1347399059334516736  0.136905\n",
       "1  1347399060219695104  0.098788\n",
       "2  1347399060236369922  0.400000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_corona_tweets_train_filtered.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning helper version 1.0\n"
     ]
    }
   ],
   "source": [
    "cleaningHelper = CleaningHelper(version = \"1.0\")\n",
    "print(cleaningHelper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>PercNotNull</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tweet_id</th>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rate</th>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Total  PercNotNull\n",
       "tweet_id       0        100.0\n",
       "rate           0        100.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaningHelper.get_nulls_data(df_corona_tweets_train_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.450000    0.068\n",
       " 0.136364    0.054\n",
       " 0.250000    0.045\n",
       " 0.500000    0.032\n",
       "-0.100000    0.028\n",
       "             ...  \n",
       " 0.162476    0.001\n",
       " 0.102778    0.001\n",
       " 0.016667    0.001\n",
       "-0.273148    0.001\n",
       "-0.080000    0.001\n",
       "Name: rate, Length: 294, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_corona_tweets_train_filtered.rate.value_counts()/len(df_corona_tweets_train_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"background-color:powderblue;\">Data cleaning</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I decided to use the largest one\n",
    "spacy_lg = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sets of punctuation in variable result \n",
    "punctuation_str = string.punctuation  \n",
    "punctuation_str #I want to know if @ is actually include"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stop words Set\n",
    "#stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
    "stop_words = cleaningHelper.get_custom_stop_words(spacy_ = spacy_lg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#English parser object\n",
    "parser = spacy.lang.en.English()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning Tweets version 1.0\n"
     ]
    }
   ],
   "source": [
    "cleaningTweets = CleaningTweets(version = \"1.0\", spacy_ = spacy_lg, parser_ = parser, punctuation_str_ = punctuation_str, stop_words_ = stop_words)\n",
    "print(cleaningTweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitterAuthentication = TwitterAuthentication(version = \"1.0\")\n",
    "api = twitterAuthentication.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting to sqlite3 database\n",
    "dbConn = Sqlite3Db('social_network.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating tweets table\n",
    "dbConn.query('''CREATE TABLE IF NOT EXISTS TweetsTraining(insert_timestamp timestamp, tweet_id TEXT, rate TEXT, tweet_text TEXT)''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLEAN_TRAINING = False\n",
    "#Cleaning TweetsTraining table\n",
    "if CLEAN_TRAINING:\n",
    "    del_stm_str = \"\"\"DELETE FROM TweetsTraining;\"\"\"\n",
    "    dbConn.query(sqlStm=del_stm_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180 180 2021-01-10 10:38:36\n"
     ]
    }
   ],
   "source": [
    "twitterProcess = TwitterProcess(api = api, dbConn = dbConn)\n",
    "limit, remaining, next_reset_time = twitterProcess.get_api_limits()\n",
    "print(limit, remaining, next_reset_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a = twitterProcess.get_tweet_text_by_id(tweet_id_ = \"1347399060739796992\")\n",
    "#a = twitterProcess.get_tweet_text_by_id(tweet_id_ = \"1347399060219695104\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#status = api.get_status(1347399060219695104)\n",
    "#status = status.text\n",
    "#status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start = time.time()\n",
    "#start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlite3DbHelper = Sqlite3DbHelper(dbConn = dbConn)\n",
    "#query_stm_res = sqlite3DbHelper.get_count_stm(sql_stm_res)\n",
    "#query_stm_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for index, row in df_corona_tweets_train_filtered.iterrows():\n",
    "#    #print(index)\n",
    "#    print(row[1])\n",
    "#    rate_ = f\"{row[1]:.0f}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if CLEAN_TRAINING:\n",
    "    start = time.time()\n",
    "    tweet_text_list = []\n",
    "    for index, row in df_corona_tweets_train_filtered.iterrows():\n",
    "        #print(index)\n",
    "        #print(row[0])\n",
    "\n",
    "        tweet_id_ = f\"{row[0]:.0f}\"\n",
    "        rate_ = f\"{row[1]:.16f}\"\n",
    "        #print(f\"{tweet_id_}\")\n",
    "        #if index == 9:\n",
    "        #    break\n",
    "\n",
    "        #print(tweet_id_)\n",
    "        #print(twitterProcess.get_tweet_text_by_id(tweet_id_ = tweet_id_))\n",
    "        twitter_status_ = twitterProcess.get_tweet_text_by_id(tweet_id_ = tweet_id_)\n",
    "        ins_stm_str = \"\"\"INSERT INTO TweetsTraining (insert_timestamp, tweet_id, rate, tweet_text) VALUES (?,?,?,?);\"\"\"\n",
    "        #if len(twitter_status_.strip()) > 0:\n",
    "\n",
    "        insert_timestamp = sqlite3DbHelper.get_timestamp_now()\n",
    "\n",
    "        data_tuple = (insert_timestamp, tweet_id_, rate_, twitter_status_)\n",
    "        dbConn.query(sqlStm=ins_stm_str, sqlStmPrm=data_tuple)\n",
    "        sql_stm_res = dbConn.cursor.fetchall()\n",
    "        tweet_text_list.append(twitter_status_)\n",
    "\n",
    "    print('Before End time: {} mins'.format(round((time.time() - start) / 60, 2)))\n",
    "    df_corona_tweets_train_filtered[\"tweet_text\"] = tweet_text_list\n",
    "    print('End time: {} mins'.format(round((time.time() - start) / 60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try:\n",
    "#    tweet_text_ = twitterProcess.get_tweet_text_by_id(tweet_id_ = \"1347399060739796992\")\n",
    "#    print(tweet_text_)\n",
    "#except tweepy.TweepError as e:\n",
    "#    print(e.message[0]['code'])\n",
    "#    print(e.args[0][0]['code'])\n",
    "#    #print(\"Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_tt_stm_str = '''SELECT insert_timestamp, tweet_id, rate, tweet_text FROM TweetsTraining WHERE length(trim(tweet_text)) > 0;'''\n",
    "\n",
    "df_tweets_training_sql_ori = pd.read_sql_query(sel_tt_stm_str, dbConn.conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>insert_timestamp</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>rate</th>\n",
       "      <th>tweet_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-10 08:23:14.641840</td>\n",
       "      <td>1347399060219695104</td>\n",
       "      <td>0.0987878787878788</td>\n",
       "      <td>RT @nytimes: The U.S. reported 4,000 coronavir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-10 08:23:15.512763</td>\n",
       "      <td>1347399060341272576</td>\n",
       "      <td>0.1821428571428571</td>\n",
       "      <td>RT @FOX4: The U.S. registered more COVID-19 de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-10 08:23:15.865122</td>\n",
       "      <td>1347399060588818432</td>\n",
       "      <td>0.1666666666666666</td>\n",
       "      <td>RT @NewYearsDani: if you're angry, stop spendi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            insert_timestamp             tweet_id                rate  \\\n",
       "0 2021-01-10 08:23:14.641840  1347399060219695104  0.0987878787878788   \n",
       "1 2021-01-10 08:23:15.512763  1347399060341272576  0.1821428571428571   \n",
       "2 2021-01-10 08:23:15.865122  1347399060588818432  0.1666666666666666   \n",
       "\n",
       "                                          tweet_text  \n",
       "0  RT @nytimes: The U.S. reported 4,000 coronavir...  \n",
       "1  RT @FOX4: The U.S. registered more COVID-19 de...  \n",
       "2  RT @NewYearsDani: if you're angry, stop spendi...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets_training_sql_ori.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_training_sql_cleaned = df_tweets_training_sql_ori.copy()\n",
    "df_tweets_training_sql_cleaned[\"tweet_vector\"] = df_tweets_training_sql_cleaned[\"tweet_text\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_training_sql_cleaned[\"tweet_vector\"] = df_tweets_training_sql_cleaned[\"tweet_text\"].apply(lambda x: cleaningTweets.do_spacy_tokenizer(token_ = x) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>insert_timestamp</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>rate</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>tweet_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-10 08:23:14.641840</td>\n",
       "      <td>1347399060219695104</td>\n",
       "      <td>0.0987878787878788</td>\n",
       "      <td>RT @nytimes: The U.S. reported 4,000 coronavir...</td>\n",
       "      <td>[u.s., reported, 4,000, coronavirus, deaths, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-10 08:23:15.512763</td>\n",
       "      <td>1347399060341272576</td>\n",
       "      <td>0.1821428571428571</td>\n",
       "      <td>RT @FOX4: The U.S. registered more COVID-19 de...</td>\n",
       "      <td>[u.s., registered, covid-19, deaths, single, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-10 08:23:15.865122</td>\n",
       "      <td>1347399060588818432</td>\n",
       "      <td>0.1666666666666666</td>\n",
       "      <td>RT @NewYearsDani: if you're angry, stop spendi...</td>\n",
       "      <td>[angry, stop, spending, afraid, stop, spending...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            insert_timestamp             tweet_id                rate  \\\n",
       "0 2021-01-10 08:23:14.641840  1347399060219695104  0.0987878787878788   \n",
       "1 2021-01-10 08:23:15.512763  1347399060341272576  0.1821428571428571   \n",
       "2 2021-01-10 08:23:15.865122  1347399060588818432  0.1666666666666666   \n",
       "\n",
       "                                          tweet_text  \\\n",
       "0  RT @nytimes: The U.S. reported 4,000 coronavir...   \n",
       "1  RT @FOX4: The U.S. registered more COVID-19 de...   \n",
       "2  RT @NewYearsDani: if you're angry, stop spendi...   \n",
       "\n",
       "                                        tweet_vector  \n",
       "0  [u.s., reported, 4,000, coronavirus, deaths, t...  \n",
       "1  [u.s., registered, covid-19, deaths, single, d...  \n",
       "2  [angry, stop, spending, afraid, stop, spending...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets_training_sql_cleaned.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_training_sql_model = df_tweets_training_sql_cleaned.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_training_sql_model = df_tweets_training_sql_model[df_tweets_training_sql_model.tweet_vector.str.len()>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>insert_timestamp</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>rate</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>tweet_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-10 08:23:14.641840</td>\n",
       "      <td>1347399060219695104</td>\n",
       "      <td>0.0987878787878788</td>\n",
       "      <td>RT @nytimes: The U.S. reported 4,000 coronavir...</td>\n",
       "      <td>[u.s., reported, 4,000, coronavirus, deaths, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-10 08:23:15.512763</td>\n",
       "      <td>1347399060341272576</td>\n",
       "      <td>0.1821428571428571</td>\n",
       "      <td>RT @FOX4: The U.S. registered more COVID-19 de...</td>\n",
       "      <td>[u.s., registered, covid-19, deaths, single, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-10 08:23:15.865122</td>\n",
       "      <td>1347399060588818432</td>\n",
       "      <td>0.1666666666666666</td>\n",
       "      <td>RT @NewYearsDani: if you're angry, stop spendi...</td>\n",
       "      <td>[angry, stop, spending, afraid, stop, spending...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            insert_timestamp             tweet_id                rate  \\\n",
       "0 2021-01-10 08:23:14.641840  1347399060219695104  0.0987878787878788   \n",
       "1 2021-01-10 08:23:15.512763  1347399060341272576  0.1821428571428571   \n",
       "2 2021-01-10 08:23:15.865122  1347399060588818432  0.1666666666666666   \n",
       "\n",
       "                                          tweet_text  \\\n",
       "0  RT @nytimes: The U.S. reported 4,000 coronavir...   \n",
       "1  RT @FOX4: The U.S. registered more COVID-19 de...   \n",
       "2  RT @NewYearsDani: if you're angry, stop spendi...   \n",
       "\n",
       "                                        tweet_vector  \n",
       "0  [u.s., reported, 4,000, coronavirus, deaths, t...  \n",
       "1  [u.s., registered, covid-19, deaths, single, d...  \n",
       "2  [angry, stop, spending, afraid, stop, spending...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets_training_sql_model.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 10:33:55: collecting all words and their counts\n",
      "INFO - 10:33:55: PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
      "INFO - 10:33:55: collected 4247 word types from a corpus of 3688 words (unigram + bigrams) and 436 sentences\n",
      "INFO - 10:33:55: using 4247 counts as vocab in Phrases<0 vocab, min_count=1, threshold=10.0, max_vocab_size=40000000>\n",
      "INFO - 10:33:55: source_vocab length 4247\n",
      "INFO - 10:33:55: Phraser built with 253 phrasegrams\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['u.s.',\n",
       " 'registered',\n",
       " 'covid-19_deaths',\n",
       " 'single_day',\n",
       " '--',\n",
       " 'nearly',\n",
       " '3,900',\n",
       " '--',\n",
       " 'day',\n",
       " 'mob',\n",
       " 'attack']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = [row for row in df_tweets_training_sql_model.tweet_vector]\n",
    "phrases = Phrases(sent, min_count=1, progress_per=50000)\n",
    "bigram = Phraser(phrases)\n",
    "sentences = bigram[sent]\n",
    "sentences[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 10:44:41: collecting all words and their counts\n",
      "INFO - 10:44:41: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO - 10:44:41: collected 1882 word types from a corpus of 3067 raw words and 436 sentences\n",
      "INFO - 10:44:41: Loading a fresh vocabulary\n",
      "INFO - 10:44:41: effective_min_count=3 retains 187 unique words (9% of original 1882, drops 1695)\n",
      "INFO - 10:44:41: effective_min_count=3 leaves 1082 word corpus (35% of original 3067, drops 1985)\n",
      "INFO - 10:44:41: deleting the raw counts dictionary of 1882 items\n",
      "INFO - 10:44:41: sample=1e-05 downsamples 187 most-common words\n",
      "INFO - 10:44:41: downsampling leaves estimated 46 word corpus (4.3% of prior 1082)\n",
      "INFO - 10:44:41: estimated required memory for 187 words and 300 dimensions: 542300 bytes\n",
      "INFO - 10:44:41: resetting layer weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build vocab: 0.0 mins\n"
     ]
    }
   ],
   "source": [
    "w2v_model = Word2Vec(min_count=3,\n",
    "                     window=4,\n",
    "                     size=300,\n",
    "                     sample=1e-5, \n",
    "                     alpha=0.03, \n",
    "                     min_alpha=0.0007, \n",
    "                     negative=20,\n",
    "                     workers=multiprocessing.cpu_count()-1)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "w2v_model.build_vocab(sentences, progress_per=50000)\n",
    "\n",
    "print('Time to build vocab: {} mins'.format(round((time.time() - start) / 60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 10:44:55: training model with 3 workers on 187 vocabulary and 300 features, using sg=0 hs=0 sample=1e-05 negative=20 window=4\n",
      "INFO - 10:44:56: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:44:56: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:44:56: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:44:56: EPOCH - 1 : training on 3067 raw words (42 effective words) took 0.0s, 1462 effective words/s\n",
      "INFO - 10:44:56: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:44:56: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:44:56: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:44:56: EPOCH - 2 : training on 3067 raw words (46 effective words) took 0.0s, 1846 effective words/s\n",
      "INFO - 10:44:56: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:44:56: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:44:56: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:44:56: EPOCH - 3 : training on 3067 raw words (35 effective words) took 0.0s, 785 effective words/s\n",
      "INFO - 10:44:57: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:44:57: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:44:57: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:44:57: EPOCH - 4 : training on 3067 raw words (55 effective words) took 0.0s, 1115 effective words/s\n",
      "INFO - 10:44:57: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:44:57: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:44:57: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:44:57: EPOCH - 5 : training on 3067 raw words (49 effective words) took 0.0s, 990 effective words/s\n",
      "INFO - 10:44:57: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:44:57: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:44:57: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:44:57: EPOCH - 6 : training on 3067 raw words (48 effective words) took 0.1s, 550 effective words/s\n",
      "INFO - 10:44:57: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:44:57: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:44:57: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:44:57: EPOCH - 7 : training on 3067 raw words (44 effective words) took 0.1s, 724 effective words/s\n",
      "INFO - 10:44:57: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:44:57: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:44:57: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:44:57: EPOCH - 8 : training on 3067 raw words (48 effective words) took 0.1s, 814 effective words/s\n",
      "INFO - 10:44:57: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:44:57: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:44:57: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:44:57: EPOCH - 9 : training on 3067 raw words (47 effective words) took 0.1s, 875 effective words/s\n",
      "INFO - 10:44:57: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:44:57: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:44:57: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:44:57: EPOCH - 10 : training on 3067 raw words (38 effective words) took 0.1s, 528 effective words/s\n",
      "INFO - 10:44:57: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:44:57: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:44:57: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:44:57: EPOCH - 11 : training on 3067 raw words (36 effective words) took 0.1s, 577 effective words/s\n",
      "INFO - 10:44:58: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:44:58: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:44:58: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:44:58: EPOCH - 12 : training on 3067 raw words (36 effective words) took 0.0s, 754 effective words/s\n",
      "INFO - 10:44:58: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:44:58: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:44:58: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:44:58: EPOCH - 13 : training on 3067 raw words (44 effective words) took 0.2s, 181 effective words/s\n",
      "INFO - 10:44:59: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:44:59: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:44:59: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:44:59: EPOCH - 14 : training on 3067 raw words (40 effective words) took 0.1s, 505 effective words/s\n",
      "INFO - 10:44:59: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:44:59: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:44:59: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:44:59: EPOCH - 15 : training on 3067 raw words (34 effective words) took 0.1s, 291 effective words/s\n",
      "INFO - 10:44:59: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:44:59: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:44:59: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:44:59: EPOCH - 16 : training on 3067 raw words (60 effective words) took 0.1s, 706 effective words/s\n",
      "INFO - 10:44:59: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:44:59: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:44:59: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:44:59: EPOCH - 17 : training on 3067 raw words (46 effective words) took 0.1s, 504 effective words/s\n",
      "INFO - 10:44:59: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:44:59: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:44:59: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:44:59: EPOCH - 18 : training on 3067 raw words (48 effective words) took 0.1s, 437 effective words/s\n",
      "INFO - 10:44:59: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:44:59: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:44:59: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:44:59: EPOCH - 19 : training on 3067 raw words (54 effective words) took 0.1s, 586 effective words/s\n",
      "INFO - 10:44:59: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:44:59: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:44:59: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:44:59: EPOCH - 20 : training on 3067 raw words (37 effective words) took 0.1s, 462 effective words/s\n",
      "INFO - 10:44:59: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:44:59: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:44:59: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:44:59: EPOCH - 21 : training on 3067 raw words (47 effective words) took 0.1s, 751 effective words/s\n",
      "INFO - 10:45:00: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:45:00: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:45:00: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:45:00: EPOCH - 22 : training on 3067 raw words (50 effective words) took 0.1s, 662 effective words/s\n",
      "INFO - 10:45:00: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:45:00: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:45:00: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:45:00: EPOCH - 23 : training on 3067 raw words (44 effective words) took 0.1s, 475 effective words/s\n",
      "INFO - 10:45:00: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:45:00: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:45:00: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:45:00: EPOCH - 24 : training on 3067 raw words (46 effective words) took 0.1s, 609 effective words/s\n",
      "INFO - 10:45:00: worker thread finished; awaiting finish of 2 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 10:45:00: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:45:00: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:45:00: EPOCH - 25 : training on 3067 raw words (44 effective words) took 0.1s, 368 effective words/s\n",
      "INFO - 10:45:00: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:45:00: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:45:00: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:45:00: EPOCH - 26 : training on 3067 raw words (46 effective words) took 0.1s, 624 effective words/s\n",
      "INFO - 10:45:00: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:45:00: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:45:00: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:45:00: EPOCH - 27 : training on 3067 raw words (52 effective words) took 0.1s, 1021 effective words/s\n",
      "INFO - 10:45:00: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:45:00: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:45:00: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:45:00: EPOCH - 28 : training on 3067 raw words (51 effective words) took 0.1s, 987 effective words/s\n",
      "INFO - 10:45:00: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:45:00: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:45:00: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:45:00: EPOCH - 29 : training on 3067 raw words (39 effective words) took 0.0s, 834 effective words/s\n",
      "INFO - 10:45:00: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:45:00: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:45:00: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:45:00: EPOCH - 30 : training on 3067 raw words (50 effective words) took 0.0s, 1096 effective words/s\n",
      "INFO - 10:45:00: training on a 92010 raw words (1356 effective words) took 5.0s, 273 effective words/s\n",
      "INFO - 10:45:00: precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train the model: 0.08 mins\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=30, report_delay=1)\n",
    "\n",
    "print('Time to train the model: {} mins'.format(round((time.time() - start) / 60, 2)))\n",
    "\n",
    "w2v_model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 10:45:08: saving Word2Vec object under word2vec.model, separately None\n",
      "INFO - 10:45:08: not storing attribute vectors_norm\n",
      "INFO - 10:45:08: not storing attribute cum_table\n",
      "INFO - 10:45:08: saved word2vec.model\n"
     ]
    }
   ],
   "source": [
    "w2v_model.save(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Close database\n",
    "dbConn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsfinalproject]",
   "language": "python",
   "name": "conda-env-dsfinalproject-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
