{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_a2hajcA99-K"
   },
   "source": [
    "![BTS](https://github.com/vfp1/bts-dsf-2020/blob/main/Logo-BTS.jpg?raw=1)\n",
    "\n",
    "# Session /: Text processing - Introduction to Spacy\n",
    "\n",
    "### Victor F. Pajuelo Madrigal <victor.pajuelo@bts.tech> - Data Science Foundations (2020-11-17)\n",
    "\n",
    "Open this notebook in Google Colaboratory: [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/vfp1/bts-dsf-2020/blob/main/Session_7/07_Text_processing.ipynb)\n",
    "\n",
    "**Resources:**\n",
    "* Spacy website"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DTIcPknwQz5z"
   },
   "source": [
    "# Spacy installation\n",
    "\n",
    "```\n",
    "$ conda activate bts36\n",
    "$ conda install -c conda-forge spacy\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oabpc-xuVxAQ"
   },
   "source": [
    "# Spacy introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2QHBivImfOvp"
   },
   "source": [
    "## Import language models \n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "$ python -m spacy download en_core_web_sm\n",
    "$ python -m spacy download en\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nPv81PAORYB7",
    "outputId": "d0c8c35a-642b-4ee6-f482-43bf0e5938ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_sm==2.2.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.0/en_core_web_sm-2.2.0.tar.gz#egg=en_core_web_sm==2.2.0 in /home/scientist/anaconda3/lib/python3.7/site-packages (2.2.0)\n",
      "Requirement already satisfied: spacy>=2.2.0 in /home/scientist/anaconda3/lib/python3.7/site-packages (from en_core_web_sm==2.2.0) (2.2.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/scientist/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.0->en_core_web_sm==2.2.0) (1.0.4)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /home/scientist/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.0->en_core_web_sm==2.2.0) (0.8.0)\n",
      "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /home/scientist/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.0->en_core_web_sm==2.2.0) (0.9.6)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/scientist/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.0->en_core_web_sm==2.2.0) (2.22.0)\n",
      "Requirement already satisfied: thinc<7.2.0,>=7.1.1 in /home/scientist/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.0->en_core_web_sm==2.2.0) (7.1.1)\n",
      "Requirement already satisfied: srsly<1.1.0,>=0.1.0 in /home/scientist/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.0->en_core_web_sm==2.2.0) (1.0.4)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /home/scientist/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.0->en_core_web_sm==2.2.0) (0.4.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/scientist/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.0->en_core_web_sm==2.2.0) (1.16.4)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/scientist/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.0->en_core_web_sm==2.2.0) (2.0.4)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/scientist/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.0->en_core_web_sm==2.2.0) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/scientist/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->en_core_web_sm==2.2.0) (1.24.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/scientist/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->en_core_web_sm==2.2.0) (2019.6.16)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/scientist/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->en_core_web_sm==2.2.0) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/scientist/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->en_core_web_sm==2.2.0) (3.0.4)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /home/scientist/anaconda3/lib/python3.7/site-packages (from thinc<7.2.0,>=7.1.1->spacy>=2.2.0->en_core_web_sm==2.2.0) (4.32.1)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8mQRg-8jfzDI",
    "outputId": "3d5d38cb-8111-4882-8bee-ca0ee4ca9530"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_sm==2.2.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.0/en_core_web_sm-2.2.0.tar.gz#egg=en_core_web_sm==2.2.0 in /home/scientist/anaconda3/lib/python3.7/site-packages (2.2.0)\n",
      "Requirement already satisfied: spacy>=2.2.0 in /home/scientist/anaconda3/lib/python3.7/site-packages (from en_core_web_sm==2.2.0) (2.2.1)\n",
      "Requirement already satisfied: srsly<1.1.0,>=0.1.0 in /home/scientist/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.0->en_core_web_sm==2.2.0) (1.0.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/scientist/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.0->en_core_web_sm==2.2.0) (2.22.0)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /home/scientist/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.0->en_core_web_sm==2.2.0) (0.4.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/scientist/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.0->en_core_web_sm==2.2.0) (1.0.4)\n",
      "Requirement already satisfied: thinc<7.2.0,>=7.1.1 in /home/scientist/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.0->en_core_web_sm==2.2.0) (7.1.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/scientist/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.0->en_core_web_sm==2.2.0) (1.16.4)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /home/scientist/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.0->en_core_web_sm==2.2.0) (0.8.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/scientist/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.0->en_core_web_sm==2.2.0) (2.0.4)\n",
      "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /home/scientist/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.0->en_core_web_sm==2.2.0) (0.9.6)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/scientist/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.0->en_core_web_sm==2.2.0) (3.0.4)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/scientist/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->en_core_web_sm==2.2.0) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/scientist/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->en_core_web_sm==2.2.0) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/scientist/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->en_core_web_sm==2.2.0) (2019.6.16)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/scientist/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->en_core_web_sm==2.2.0) (1.24.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /home/scientist/anaconda3/lib/python3.7/site-packages (from thinc<7.2.0,>=7.1.1->spacy>=2.2.0->en_core_web_sm==2.2.0) (4.32.1)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
      "/home/scientist/anaconda3/lib/python3.7/site-packages/en_core_web_sm -->\n",
      "/home/scientist/anaconda3/lib/python3.7/site-packages/spacy/data/en\n",
      "You can now load the model via spacy.load('en')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UmwJHdwEU4uM"
   },
   "source": [
    "Once the model is downloaded and installed, we can load it as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "IuuFgOdRRWif"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oDZS9UkeY3Td"
   },
   "source": [
    "## Linguistic annotations\n",
    "\n",
    "spaCy's linguistic annotation types:\n",
    "\n",
    "*   Word types\n",
    "*   Parts of speech\n",
    "*   How words are related to each other\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b-H7rJT8WNrg"
   },
   "source": [
    "### Word and sentence tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Nuob2h_df3mp"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "kNGRET97Wj9R"
   },
   "outputs": [],
   "source": [
    "text_sentence_1 = \"This is a class about text processing.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MX8sFJkkW1OJ",
    "outputId": "a2734bd3-c33d-4fe8-d6d0-7aeba2c3a797"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We pass the sentence to the doc\n",
    "doc1 = nlp(text_sentence_1)\n",
    "type(doc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BX67YuReZgbC"
   },
   "source": [
    "[What is a **Doc**?](https://spacy.io/api/doc) It is a sequence of Token objects. Access sentences and named entities, export annotations to numpy arrays, losslessly serialize to compressed binary strings.\n",
    "\n",
    "And [what is a **Token**?](https://spacy.io/api/token) It is a word, punctuation symbol, whitespace, etcetera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aLRjNrFIX87p",
    "outputId": "22120470-19cc-4a3e-b87a-f171b56d6e11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This\n",
      "is\n",
      "a\n",
      "class\n",
      "about\n",
      "text\n",
      "processing\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "# Let's tokenize th sentence\n",
    "for token in doc1:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iHZ3mJkDbsHk",
    "outputId": "440bd0e4-5303-434a-f0c0-e4bccddd86d0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "This"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kCs2uD4ubz7h",
    "outputId": "4748eb9b-c7e9-4aa3-e6f2-5caa05b7792e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MwZLWEsWaill"
   },
   "source": [
    "#### Linguistic features/annotation\n",
    "spaCy does not only have a record the position as if we will be splitting the sentence. spaCy records the grammatical structure of the sentence. \n",
    "\n",
    "So after tokenization (splitting the sentence into the individual components), spaCy can do **Part-of-speech** (POS) tagging. This is done by using spaCy's statistical models to make predictions of what each token is. For instance, a word following \"the\" in the English is most likely a noun. And that's why we need language models.\n",
    "\n",
    "---\n",
    "\n",
    "We have the following features that we can get per token:\n",
    "\n",
    "*   **Text**: The original word text.\n",
    "*   **Lemma**: The base form of the word.\n",
    "*   **POS**: The simple part-of-speech tag.\n",
    "*   **Tag**: The detailed part-of-speech tag.\n",
    "*   **Dep**: Syntactic dependency, i.e. the relation between tokens.\n",
    "*   **Shape**: The word shape – capitalization, punctuation, digits.\n",
    "*   **is alpha**: Is the token an alphanumeric character?\n",
    "*   **is stop**: Is the token part of a stop list, i.e. the most common words of the language?\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jfW-ItssX_V3",
    "outputId": "dbc0e0f1-a85c-40c1-cf60-7f39eaf8bce2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DET det\n",
      "coffee NOUN nsubj\n",
      "this DET det\n",
      "morning NOUN npadvmod\n",
      "costed VERB ccomp\n",
      "me PRON dative\n",
      "$ SYM nmod\n",
      "4 NUM dobj\n",
      ", PUNCT punct\n",
      "that PRON nsubj\n",
      "is AUX ROOT\n",
      "extremely ADV advmod\n",
      "expensive ADJ acomp\n",
      "! PUNCT punct\n"
     ]
    }
   ],
   "source": [
    "text_sentence_2 = \"The coffee this morning costed me $4, that is extremely expensive!\"\n",
    "doc2 = nlp(text_sentence_2)\n",
    "\n",
    "for token in doc2:\n",
    "    print(token.text, token.pos_, token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "KEthxKBmtMGD",
    "outputId": "323f8cdf-7e4c-4e41-df2d-0b297ec82a63"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'noun phrase as adverbial modifier'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain(\"npadvmod\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 483
    },
    "id": "4wRjlK2uh4pL",
    "outputId": "ee086b8c-e1c2-4899-995e-e5dd795af027"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALPHA</th>\n",
       "      <th>DEP</th>\n",
       "      <th>LEMMA</th>\n",
       "      <th>POS</th>\n",
       "      <th>SHAPE</th>\n",
       "      <th>STOP</th>\n",
       "      <th>TAG</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>det</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>Xxx</td>\n",
       "      <td>True</td>\n",
       "      <td>DT</td>\n",
       "      <td>The</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>coffee</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>False</td>\n",
       "      <td>NN</td>\n",
       "      <td>coffee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>det</td>\n",
       "      <td>this</td>\n",
       "      <td>DET</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>DT</td>\n",
       "      <td>this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>npadvmod</td>\n",
       "      <td>morning</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>False</td>\n",
       "      <td>NN</td>\n",
       "      <td>morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>ccomp</td>\n",
       "      <td>cost</td>\n",
       "      <td>VERB</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>False</td>\n",
       "      <td>VBD</td>\n",
       "      <td>costed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>True</td>\n",
       "      <td>dative</td>\n",
       "      <td>-PRON-</td>\n",
       "      <td>PRON</td>\n",
       "      <td>xx</td>\n",
       "      <td>True</td>\n",
       "      <td>PRP</td>\n",
       "      <td>me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>False</td>\n",
       "      <td>nmod</td>\n",
       "      <td>$</td>\n",
       "      <td>SYM</td>\n",
       "      <td>$</td>\n",
       "      <td>False</td>\n",
       "      <td>$</td>\n",
       "      <td>$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>False</td>\n",
       "      <td>dobj</td>\n",
       "      <td>4</td>\n",
       "      <td>NUM</td>\n",
       "      <td>d</td>\n",
       "      <td>False</td>\n",
       "      <td>CD</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>False</td>\n",
       "      <td>punct</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>,</td>\n",
       "      <td>False</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>True</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>that</td>\n",
       "      <td>PRON</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>WDT</td>\n",
       "      <td>that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>True</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>be</td>\n",
       "      <td>AUX</td>\n",
       "      <td>xx</td>\n",
       "      <td>True</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>True</td>\n",
       "      <td>advmod</td>\n",
       "      <td>extremely</td>\n",
       "      <td>ADV</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>False</td>\n",
       "      <td>RB</td>\n",
       "      <td>extremely</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>True</td>\n",
       "      <td>acomp</td>\n",
       "      <td>expensive</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>False</td>\n",
       "      <td>JJ</td>\n",
       "      <td>expensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>False</td>\n",
       "      <td>punct</td>\n",
       "      <td>!</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>!</td>\n",
       "      <td>False</td>\n",
       "      <td>.</td>\n",
       "      <td>!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ALPHA       DEP      LEMMA    POS SHAPE   STOP  TAG       TEXT\n",
       "0    True       det        the    DET   Xxx   True   DT        The\n",
       "1    True     nsubj     coffee   NOUN  xxxx  False   NN     coffee\n",
       "2    True       det       this    DET  xxxx   True   DT       this\n",
       "3    True  npadvmod    morning   NOUN  xxxx  False   NN    morning\n",
       "4    True     ccomp       cost   VERB  xxxx  False  VBD     costed\n",
       "5    True    dative     -PRON-   PRON    xx   True  PRP         me\n",
       "6   False      nmod          $    SYM     $  False    $          $\n",
       "7   False      dobj          4    NUM     d  False   CD          4\n",
       "8   False     punct          ,  PUNCT     ,  False    ,          ,\n",
       "9    True     nsubj       that   PRON  xxxx   True  WDT       that\n",
       "10   True      ROOT         be    AUX    xx   True  VBZ         is\n",
       "11   True    advmod  extremely    ADV  xxxx  False   RB  extremely\n",
       "12   True     acomp  expensive    ADJ  xxxx  False   JJ  expensive\n",
       "13  False     punct          !  PUNCT     !  False    .          !"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can build a Pandas Dataframe with the contents of a token/doc loop, just for nice visualization\n",
    "import pandas as pd\n",
    "\n",
    "d = []\n",
    "for token in doc2:\n",
    "    d.append({'TEXT': token.text, 'LEMMA': token.lemma_, \n",
    "              'POS': token.pos_, 'TAG': token.tag_,\n",
    "              'DEP': token.dep_, 'SHAPE': token.shape_,\n",
    "              'ALPHA': token.is_alpha, 'STOP': token.is_stop})\n",
    "\n",
    "spacy_dataframe = pd.DataFrame(d)\n",
    "spacy_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uUrOgHNmelLB"
   },
   "source": [
    "#### Do not feel lost! Let's visualize this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "mlStXKJZenzG",
    "outputId": "86f9535d-2056-408f-a8bb-cde63c084842"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'verb, 3rd person singular present'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can use spacy.explain when lost\n",
    "spacy.explain(\"VBZ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "JkIRfHLbkaF8",
    "outputId": "4cd378dd-6ed8-4d14-a291-df8de223539e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'adverbial modifier'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain(\"advmod\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "fyxDoHVFkdV2",
    "outputId": "838c0583-d471-475e-c975-2536b5903e5c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"6f83df9c29984a0886a206ed96be6596-0\" class=\"displacy\" width=\"1250\" height=\"337.0\" direction=\"ltr\" style=\"max-width: none; height: 337.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">The</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"150\">coffee</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"150\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"250\">this</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"250\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"350\">morning</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"350\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"450\">costed</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"450\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"550\">me</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"550\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"650\">$</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"650\">SYM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">4,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"850\">that</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"850\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"950\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"950\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1050\">extremely</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1050\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1150\">expensive!</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1150\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6f83df9c29984a0886a206ed96be6596-0-0\" stroke-width=\"2px\" d=\"M70,202.0 C70,152.0 135.0,152.0 135.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6f83df9c29984a0886a206ed96be6596-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,204.0 L62,192.0 78,192.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6f83df9c29984a0886a206ed96be6596-0-1\" stroke-width=\"2px\" d=\"M170,202.0 C170,52.0 445.0,52.0 445.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6f83df9c29984a0886a206ed96be6596-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M170,204.0 L162,192.0 178,192.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6f83df9c29984a0886a206ed96be6596-0-2\" stroke-width=\"2px\" d=\"M270,202.0 C270,152.0 335.0,152.0 335.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6f83df9c29984a0886a206ed96be6596-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M270,204.0 L262,192.0 278,192.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6f83df9c29984a0886a206ed96be6596-0-3\" stroke-width=\"2px\" d=\"M370,202.0 C370,152.0 435.0,152.0 435.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6f83df9c29984a0886a206ed96be6596-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">npadvmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M370,204.0 L362,192.0 378,192.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6f83df9c29984a0886a206ed96be6596-0-4\" stroke-width=\"2px\" d=\"M470,202.0 C470,2.0 950.0,2.0 950.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6f83df9c29984a0886a206ed96be6596-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">ccomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M470,204.0 L462,192.0 478,192.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6f83df9c29984a0886a206ed96be6596-0-5\" stroke-width=\"2px\" d=\"M470,202.0 C470,152.0 535.0,152.0 535.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6f83df9c29984a0886a206ed96be6596-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dative</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M535.0,204.0 L543.0,192.0 527.0,192.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6f83df9c29984a0886a206ed96be6596-0-6\" stroke-width=\"2px\" d=\"M670,202.0 C670,152.0 735.0,152.0 735.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6f83df9c29984a0886a206ed96be6596-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M670,204.0 L662,192.0 678,192.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6f83df9c29984a0886a206ed96be6596-0-7\" stroke-width=\"2px\" d=\"M470,202.0 C470,52.0 745.0,52.0 745.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6f83df9c29984a0886a206ed96be6596-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M745.0,204.0 L753.0,192.0 737.0,192.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6f83df9c29984a0886a206ed96be6596-0-8\" stroke-width=\"2px\" d=\"M870,202.0 C870,152.0 935.0,152.0 935.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6f83df9c29984a0886a206ed96be6596-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M870,204.0 L862,192.0 878,192.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6f83df9c29984a0886a206ed96be6596-0-9\" stroke-width=\"2px\" d=\"M1070,202.0 C1070,152.0 1135.0,152.0 1135.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6f83df9c29984a0886a206ed96be6596-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1070,204.0 L1062,192.0 1078,192.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6f83df9c29984a0886a206ed96be6596-0-10\" stroke-width=\"2px\" d=\"M970,202.0 C970,102.0 1140.0,102.0 1140.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6f83df9c29984a0886a206ed96be6596-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">acomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1140.0,204.0 L1148.0,192.0 1132.0,192.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "# Show POS and synthatic dependencies\n",
    "displacy.render(doc2, style=\"dep\", jupyter=True, options={'distance': 100})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bigTnVjNhjT_"
   },
   "source": [
    "#### Naming entities\n",
    "\n",
    "\n",
    "\n",
    "> spaCy features an extremely fast statistical entity recognition system, that assigns labels to contiguous spans of tokens. The default model identifies a variety of named and numeric entities, including companies, locations, organizations and products. You can add arbitrary classes to the entity recognition system, and update the model with new examples.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "Nun7w-ErksfY",
    "outputId": "0c1e9f21-eeb3-4ae6-aff0-6a0acab74892"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">The coffee \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    this morning\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">TIME</span>\n",
       "</mark>\n",
       " costed me $\n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    4\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       ", that is extremely expensive!</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The entity visualizer highlights named entities and their labels in the text\n",
    "displacy.render(doc2, style=\"ent\", jupyter=True, options={'distance': 100})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9k07OV_0hNct"
   },
   "source": [
    "#### In class exercise:\n",
    "\n",
    "Try it yourself. Write a sentence, visualize the synthatic dependencies and the entities within the sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j99jqjl7hh9D"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1zXsGHrIqadY"
   },
   "source": [
    "#### Tokenization rules\n",
    "\n",
    "The tokenization applies rules specific to each language. For instance, punctuation at the end of a sentence should be split off – whereas “U.K.” should remain one token. Also don't should be split as **do** and **not** and such.\n",
    "\n",
    "Those form part of the tokenizer exceptions, that make all that decisions for each language model on whether to split a word or not.\n",
    "\n",
    "* **Tokenizer exception**: Special-case rule to split a string into several tokens or prevent a token from being split when punctuation rules are applied.\n",
    "* **Prefix**: Character(s) at the beginning, e.g. $, (, “, ¿.\n",
    "* **Suffix**: Character(s) at the end, e.g. km, ), ”, !.\n",
    "* **Infix**: Character(s) in between, e.g. -, --, /, ….\n",
    "\n",
    "If we want to change the tokenization or add some, we will need to create our own rules (rarely used unless you are dealing with scientific/slang languages)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "DS48FrWKskO3"
   },
   "outputs": [],
   "source": [
    "text_sentence_3 = \"I was accepted at UCL-CV Master in U.K., but I didn't have enough money for it!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BLSJVLMerHhf",
    "outputId": "2716a32b-ee33-431b-cf7f-a48cecdcef5f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'was',\n",
       " 'accepted',\n",
       " 'at',\n",
       " 'UCL-CV',\n",
       " 'Master',\n",
       " 'in',\n",
       " 'U.K.,',\n",
       " 'but',\n",
       " 'I',\n",
       " \"didn't\",\n",
       " 'have',\n",
       " 'enough',\n",
       " 'money',\n",
       " 'for',\n",
       " 'it!']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "With Python we can also split the text using .split().\n",
    "\n",
    "The problem is that we do not retain contextual token information.\n",
    "Such as do/not or punctuations such as commas or exclamations.\n",
    "\"\"\"\n",
    "\n",
    "text_sentence_3.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "er1OCTJSlz4u",
    "outputId": "43540239-90f7-468d-b15d-265d91fa82fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\n",
      "was\n",
      "accepted\n",
      "at\n",
      "UCL\n",
      "-\n",
      "CV\n",
      "Master\n",
      "in\n",
      "U.K.\n",
      ",\n",
      "but\n",
      "I\n",
      "did\n",
      "n't\n",
      "have\n",
      "enough\n",
      "money\n",
      "for\n",
      "it\n",
      "!\n"
     ]
    }
   ],
   "source": [
    "doc3 = nlp(text_sentence_3)\n",
    "\n",
    "for token in doc3:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RsidWPPVvgvu"
   },
   "source": [
    "##### Creating our own rule\n",
    "\n",
    "Global and language-specific tokenizer data is supplied via the language data in spacy/lang. The tokenizer exceptions define special cases like “don’t” in English, which needs to be split into two tokens: {ORTH: \"do\"} and {ORTH: \"n't\", NORM: \"not\"}. The prefixes, suffixes and infixes mostly define punctuation rules – for example, when to split off periods (at the end of a sentence), and when to leave tokens containing periods intact (abbreviations like “U.S.”).\n",
    "\n",
    "![alt text](https://spacy.io/language_data-ef63e6a58b7ec47c073fb59857a76e5f.svg)\n",
    "\n",
    "Anything that’s specific to a domain or text type – like financial trading abbreviations, or Bavarian youth slang – should be added as a special case rule to your tokenizer instance. If you’re dealing with a lot of customizations, it might make sense to create an entirely custom subclass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XspIC2OirfGu",
    "outputId": "89d3c556-203e-4963-ce58-15ccc29813ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey\n",
      ",\n",
      "gimme\n",
      "your\n",
      "money\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "text_sentence_4 = \"Hey, gimme your money\" \n",
    "\n",
    "doc4 = nlp(text_sentence_4)\n",
    "\n",
    "for token in doc4:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "ttqRCuuQw6On"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.symbols import ORTH\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\") \n",
    "\n",
    "text_sentence_4 = \"Hey, gimme your money\" \n",
    "doc4 = nlp(text_sentence_4)\n",
    "\n",
    "# Add special case rule\n",
    "special_case = [{ORTH: \"gim\"}, {ORTH: \"me\"}]\n",
    "nlp.tokenizer.add_special_case(\"gimme\", special_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NspnM88txUDc",
    "outputId": "66844448-5f18-42cc-8b9b-6f688dec996d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey\n",
      ",\n",
      "gim\n",
      "me\n",
      "your\n",
      "money\n"
     ]
    }
   ],
   "source": [
    "text_sentence_4 = \"Hey, gimme your money\" \n",
    "\n",
    "doc4 = nlp(text_sentence_4)\n",
    "\n",
    "for token in doc4:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rQwVTWHQztz8"
   },
   "source": [
    "##### Long sentences and weird spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mYIaQp2k45gd",
    "outputId": "c2a3e55f-d46c-4318-889b-5005a086734b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some\n",
      "\n",
      "\n",
      "spaces\n",
      " \n",
      "and\n",
      "\t\n",
      "tab\n",
      "characters\n"
     ]
    }
   ],
   "source": [
    "text_sentence_5 = 'Some\\nspaces  and\\ttab characters'\n",
    "\n",
    "doc5 = nlp(text_sentence_5)\n",
    "\n",
    "for token in doc5:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NVkzoQAw5FsY",
    "outputId": "bfe7684c-d3d5-4f0c-a9ec-eca11f791b78"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc5[1].is_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UEvV03B05KdP",
    "outputId": "5715cf97-5976-4250-848f-a7db290c3e2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In ancient Rome, some neighbors live in three adjacent houses.\n",
      "In the center is the house of Senex, who lives there with wife Domina, son Hero, and several slaves, including head slave Hysterium and the musical's main character Pseudolus.\n",
      "A slave belonging to Hero, Pseudolus wishes to buy, win, or steal his freedom.\n",
      "One of the neighboring houses is owned by Marcus Lycus, who is a buyer and seller of beautiful women; the other belongs to the ancient Erronius, who is abroad searching for his long-lost children (stolen in infancy by pirates).\n",
      "One day, Senex and Domina go on a trip and leave Pseudolus in charge of Hero.\n",
      "Hero confides in Pseudolus that he is in love with the lovely Philia, one of the courtesans in the House of Lycus (albeit still a virgin).\n"
     ]
    }
   ],
   "source": [
    "# Spacy can also recognize sentences without weird splits\n",
    "text_sentence_6 = \"In ancient Rome, some neighbors live in three adjacent houses. In the center is the house of Senex, who lives there with wife Domina, son Hero, and several slaves, including head slave Hysterium and the musical's main character Pseudolus. A slave belonging to Hero, Pseudolus wishes to buy, win, or steal his freedom. One of the neighboring houses is owned by Marcus Lycus, who is a buyer and seller of beautiful women; the other belongs to the ancient Erronius, who is abroad searching for his long-lost children (stolen in infancy by pirates). One day, Senex and Domina go on a trip and leave Pseudolus in charge of Hero. Hero confides in Pseudolus that he is in love with the lovely Philia, one of the courtesans in the House of Lycus (albeit still a virgin).\"\n",
    "\n",
    "doc6 = nlp(text_sentence_6)\n",
    "\n",
    "for sent in doc6.sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O1H-VPRB6W7l"
   },
   "source": [
    "### Lemmatization\n",
    "\n",
    "Lemmatization is the assignation of the base forms of words. For example, the lemma of “was” is “be”, and the lemma of “rats” is “rat”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "E19GCEnZ6P9v",
    "outputId": "8ffd26ef-2fea-48ba-f491-9ac25e3a7e6a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neighbour'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(\"they are neighbours\")[-1].lemma_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "2RXDuPHy-eTs",
    "outputId": "428c8aad-4739-46c5-fccf-ecb2f182cd21"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'be'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(\"is\")[0].lemma_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BVD7TNvv639P",
    "outputId": "9e7ab997-7203-48e8-9cf7-d519c63491b8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "In"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc6[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "ZIHap1F26_bH",
    "outputId": "59bc3ae5-b851-42b3-c53e-2c0d83250358"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'in'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc6[0].lemma_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "orAIfks77Hk_",
    "outputId": "ed41fd3d-3b44-4a26-b4b8-d52e8d4f56b9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lexeme.Lexeme at 0x7f0877c97cf0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting information about a token\n",
    "doc6.vocab['be']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KdjoTxuG7s_V"
   },
   "source": [
    "#### Dealing with STOP words\n",
    "In computing, stop words are words which are filtered out before processing of natural language data (text). Stop words are generally the most common words in a language; there is no single universal list of stop words used by all natural language processing tools, and indeed not all tools even use such a list. Some tools avoid removing stop words to support phrase search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KJjuIZla7Lqf",
    "outputId": "35d0b68f-f3c1-4a39-9acb-da1a15464776"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'what', 'five', 'along', 'put', 'become', 'to', 'amongst', 'ours', 'yourselves', 'her', 'various', 'might', 'full', 'any', 'hereafter', 'upon', 'whither', 'is', 'myself', 'elsewhere', 'throughout', 'seem', 'via', 'very', 'everywhere', 'empty', 'first', 'our', 'been', 'each', 'really', 'call', 'top', 'three', '‘d', 'enough', 'same', 'hereby', 'beside', 'onto', 'out', 'whereafter', 'sometime', '’s', '‘ve', 'get', 'nine', 'n’t', 'seems', '’ve', 'serious', 'show', 'it', 'just', 'thence', 'part', 'n‘t', 'even', 'nowhere', 'under', 'until', 'except', 'regarding', 'herself', 'in', 'besides', 'noone', 'everything', 'somehow', '’re', 'for', 'himself', 'done', 'becoming', 'who', 'make', \"'ve\", 'thereafter', 'down', 'see', 'between', 'were', 'quite', 'sometimes', 'there', 'else', 'will', 'anyhow', 'are', 'because', 'can', 'ever', 'him', 'hence', 'hundred', 'rather', 'due', 'few', 'have', 'several', 'would', 'neither', 'must', 'one', 'always', 'whereby', 'from', 'across', 'toward', 'nevertheless', 'yours', 'yourself', 'others', '’d', 'well', 'he', 'do', 'hers', 'least', 'be', 'indeed', 'me', 'please', \"'m\", 'you', 'give', 'had', 'with', 'otherwise', 'whom', 'much', 'became', 'no', 'twenty', 'former', 'afterwards', 'an', 'doing', 'within', 'why', 'thereupon', 'against', 'mostly', 'often', '‘re', 'less', 'moreover', 'since', 'own', 'amount', 'twelve', 'such', 'anything', 'back', 'so', 'something', 'yet', 'during', 'per', 'therefore', 'whoever', '‘m', 'a', 'than', 'and', 'whereupon', 'bottom', 'about', 'again', '‘ll', 'seemed', 'their', 'latter', 'whereas', 'more', 'behind', 'namely', 'fifty', 'has', 'when', 'six', 'nor', 'on', 'by', 'anywhere', 'nothing', 'forty', 'some', 'without', 'your', 'thereby', 'beforehand', 're', 'this', 'go', 'somewhere', 'below', '‘s', 'hereupon', 'front', 'she', 'almost', \"'ll\", \"'re\", 'someone', 'was', 'am', 'which', 'mine', 'whose', 'before', 'could', 'all', 'if', 'i', 'move', 'none', 'also', 'everyone', 'four', 'itself', 'last', 'themselves', 'further', 'cannot', 'whenever', 'many', 'while', 'together', 'although', 'sixty', 'latterly', 'keep', 'them', 'next', 'made', 'too', 'around', 'ten', 'though', 'using', 'two', 'or', 'how', 'formerly', 'side', 'seeming', 'that', '’ll', 'wherever', 'whole', 'into', 'wherein', 'either', 'not', 'eleven', 'here', 'beyond', 'the', 'being', 'thus', 'among', 'as', 'whatever', 'should', 'but', 'its', 'another', 'eight', 'after', 'does', 'they', 'every', 'only', 'at', 'unless', 'above', 'towards', 'used', 'off', 'these', 'those', 'take', \"'d\", 'of', 'therein', 'however', 'alone', 'third', 'my', 'whether', 'once', \"'s\", 'herein', 'us', 'ca', 'now', 'we', 'fifteen', 'did', 'still', 'over', 'anyone', 'never', \"n't\", 'anyway', 'most', '’m', 'up', 'may', 'through', 'perhaps', 'whence', 'say', 'then', 'meanwhile', 'becomes', 'his', 'where', 'name', 'other', 'nobody', 'both', 'ourselves', 'already', 'thru'}\n"
     ]
    }
   ],
   "source": [
    "# Getting STOP words\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "print(STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h6KuLWRV72_X",
    "outputId": "796d0f3c-43f1-47b5-b5cb-56093572df15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In --> is stopword in list above? --> False\n"
     ]
    }
   ],
   "source": [
    "print(doc6[0], \"--> is stopword in list above? -->\", doc6[0] in STOP_WORDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ze9L3mcL97nm"
   },
   "source": [
    "\"In\" is not found in the list of common words, however spaCy changes automatically to lower case to find that actually \"In\" is \"in\" and therefore is a stopword."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XiSaZtvq8Dun",
    "outputId": "e8c3bed3-2577-4a17-cd03-fc95e79b7ecc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc6[0].is_stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZjJ5na1b-O92"
   },
   "source": [
    "### In class exercise:\n",
    "\n",
    "Display a table with all the tokens of `text1` and the columns `[\"Text\", \"Lemma\", \"Coarse POS (pos)\", \"Fine POS (tag)\", \"Syntactic dependency\", \"Shape\", \"Alphanumeric\", \"Stop\"]`. Look in https://spacy.io/api/token#attributes for hints. Something like:\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>Text</th>\n",
    "      <th>Lemma</th>\n",
    "      <th>Coarse POS (pos)</th>\n",
    "      <th>Fine POS (tag)</th>\n",
    "      <th>Syntactic dependency</th>\n",
    "      <th>Shape</th>\n",
    "      <th>Alphanumeric</th>\n",
    "      <th>Stop</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>0</th>\n",
    "      <td>This</td>\n",
    "      <td>this</td>\n",
    "      <td>DET</td>\n",
    "      <td>DT</td>\n",
    "      <td>nsubj</td>\n",
    "      <td>Xxxx</td>\n",
    "      <td>True</td>\n",
    "      <td>False</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>1</th>\n",
    "      <td>is</td>\n",
    "      <td>be</td>\n",
    "      <td>VERB</td>\n",
    "      <td>VBZ</td>\n",
    "      <td>ROOT</td>\n",
    "      <td>xx</td>\n",
    "      <td>True</td>\n",
    "      <td>True</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>...</th>\n",
    "      <td>...</td>\n",
    "      <td>...</td>\n",
    "      <td>...</td>\n",
    "      <td>...</td>\n",
    "      <td>...</td>\n",
    "      <td>...</td>\n",
    "      <td>...</td>\n",
    "      <td>...</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "Also, create a dependency and entity graph of the sentence.\n",
    "\n",
    "Use the following sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "S-AIgn__-leF"
   },
   "outputs": [],
   "source": [
    "exercise_sentece = \"This is great! We are learning text processing with spaCy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pkru_Zpi5yhO"
   },
   "source": [
    "## spaCy pipelines\n",
    "\n",
    "When we call `nlp` on a text, spaCy tokenizes the text to produce a `Doc`. The processing pipeline has different steps that are removed from the complexity of the user but that [can be tweaked if needed](https://spacy.io/usage/processing-pipelines).\n",
    "\n",
    "![alt text](https://spacy.io/pipeline-7a14d4edd18f3edfee8f34393bff2992.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X3WXfgOF-wYg"
   },
   "source": [
    "## Entity recognition\n",
    "\n",
    "A **named entity** is a *real-world object* that’s assigned a name – for example, a person, a country, a product or a book title.\n",
    "\n",
    "\n",
    "> spaCy can recognize [many types of named entities](https://spacy.io/api/annotation#named-entities), by predicting over a language model. Results are not 100% accurate as models are statistical and depends on the examples they are trained on, but this can be fine tuned for you later on.\n",
    "\n",
    "\n",
    "\n",
    "Named entities can be accessed from the *ents* properties of a spaCy *Doc*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "9bwX_KZWP29D"
   },
   "outputs": [],
   "source": [
    "text_sentence_7 = u'Apple is looking at buying U.K. startup for 1 billion USD'\n",
    "doc7 = nlp(text_sentence_7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TqzU-QnArT9E"
   },
   "source": [
    "There are certain entity properties that can be accessed:\n",
    "\n",
    "* **Text**: The original entity text.\n",
    "* **Start**: Index of start of entity in the Doc.\n",
    "* **End**: Index of end of entity in the Doc.\n",
    "* **Label**: Entity label, i.e. type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jpeSXMhhP29H",
    "outputId": "159fd684-fe71-4f1e-e95b-b38f3f52536a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple 0 5 ORG\n",
      "U.K. 27 31 GPE\n",
      "1 billion 44 53 CARDINAL\n"
     ]
    }
   ],
   "source": [
    "for ent in doc7.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "M-kt6zFtP29K",
    "outputId": "ded27556-a899-4270-f3ab-efa7e5b0a580"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Apple\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " is looking at buying \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    U.K.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " startup for \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    1 billion\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " USD</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc7, style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 192
    },
    "id": "LBS2-ke3-vLv",
    "outputId": "47034cd6-15ba-412a-c28d-5cfb83d32417"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">In ancient \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Rome\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", some neighbors live in \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    three\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " adjacent houses. In the center is the house of \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Senex\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", who lives there with wife \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Domina\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ", son \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Hero\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ", and several slaves, including head slave Hysterium and the musical's main character \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Pseudolus\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ". A slave belonging to \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Hero\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Pseudolus\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " wishes to buy, win, or steal his freedom. \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    One\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " of the neighboring houses is owned by \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Marcus Lycus\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ", who is a buyer and seller of beautiful women; the other belongs to the ancient \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Erronius\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ", who is abroad searching for his long-lost children (stolen in infancy by pirates). \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    One day\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Senex\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Domina\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " go on a trip and leave \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Pseudolus\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " in charge of \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Hero\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ". Hero confides in \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Pseudolus\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " that he is in love with the lovely \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Philia\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", one of the courtesans in \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    the House of Lycus\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " (albeit still a virgin).</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc6, style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cTx01agLvxGi"
   },
   "source": [
    "## Word vectors and similarity\n",
    "\n",
    "The similarity or distance between two words can be done by comparing **word vectors** or *word embeddings*, which are multi-dimensional meaning representations of a word.\n",
    "\n",
    "Word vectors are usually created by using an algorithm like word2vec.\n",
    "\n",
    "To make them compact and fast, spaCy’s small models (all packages that end in sm) don’t ship with word vectors, and only include context-sensitive tensors. This means you can still use the similarity() methods to compare documents, spans and tokens – but the result won’t be as good, and individual tokens won’t have any vectors assigned. So in order to use real word vectors, you need to download a larger model, such as `en_core_web_md` or `en_core_web_lg`.\n",
    "\n",
    "**IMPORTANT!!** In Google Colab, download the following cell and then restart runtime to locate the downloaded model.\n",
    "\n",
    "A word vector looks like the following array: \n",
    "\n",
    "![alt text](https://miro.medium.com/max/560/1*Bp64BP0Buo9ZZWIyh6QzEQ.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f2lQoQpowKC-",
    "outputId": "cf738260-e2c4-4be2-bdf5-a48e6f8a36c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_md==2.2.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.2.0/en_core_web_md-2.2.0.tar.gz#egg=en_core_web_md==2.2.0 in /home/scientist/anaconda3/lib/python3.7/site-packages (2.2.0)\n",
      "Requirement already satisfied: spacy>=2.2.0 in /home/scientist/anaconda3/lib/python3.7/site-packages (from en_core_web_md==2.2.0) (2.2.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/scientist/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.0->en_core_web_md==2.2.0) (1.0.4)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/scientist/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.0->en_core_web_md==2.2.0) (1.16.4)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /home/scientist/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.0->en_core_web_md==2.2.0) (0.8.0)\n",
      "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /home/scientist/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.0->en_core_web_md==2.2.0) (0.9.6)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /home/scientist/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.0->en_core_web_md==2.2.0) (0.4.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/scientist/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.0->en_core_web_md==2.2.0) (3.0.4)\n",
      "Requirement already satisfied: srsly<1.1.0,>=0.1.0 in /home/scientist/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.0->en_core_web_md==2.2.0) (1.0.4)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/scientist/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.0->en_core_web_md==2.2.0) (2.0.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/scientist/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.0->en_core_web_md==2.2.0) (2.22.0)\n",
      "Requirement already satisfied: thinc<7.2.0,>=7.1.1 in /home/scientist/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.0->en_core_web_md==2.2.0) (7.1.1)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/scientist/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->en_core_web_md==2.2.0) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/scientist/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->en_core_web_md==2.2.0) (2019.6.16)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/scientist/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->en_core_web_md==2.2.0) (1.24.2)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/scientist/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->en_core_web_md==2.2.0) (3.0.4)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /home/scientist/anaconda3/lib/python3.7/site-packages (from thinc<7.2.0,>=7.1.1->spacy>=2.2.0->en_core_web_md==2.2.0) (4.32.1)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_md')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aWqmnIZa0yzy"
   },
   "source": [
    "The word vectors can be explored with the following techniques then:\n",
    "\n",
    "* **Text**: The original token text.\n",
    "* **has vector**: Does the token have a vector representation?\n",
    "* **Vector norm**: The L2 norm of the token’s vector (the square root of the sum of the values squared)\n",
    "* **OOV**: Out-of-vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fkPFASlR_iOI",
    "outputId": "a177b12e-f8b0-4769-a8f6-696231882fe4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog True 7.0336733 False\n",
      "cat True 6.6808186 False\n",
      "banana True 6.700014 False\n",
      "afskfsd False 0.0 True\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "tokens = nlp(\"dog cat banana afskfsd\")\n",
    "\n",
    "for token in tokens:\n",
    "    print(token.text, token.has_vector, token.vector_norm, token.is_oov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QT-fbAZf2bfB"
   },
   "source": [
    "The words “dog”, “cat” and “banana” are all pretty common in English, so they’re part of the model’s vocabulary, and come with a vector. The word “afskfsd” on the other hand is a lot less common and out-of-vocabulary – so its vector representation consists of 300 dimensions of 0, which means it’s practically nonexistent. \n",
    "\n",
    "spaCy is able to compare two objects, and make a prediction of how similar they are. Predicting similarity is useful for building recommendation systems or flagging duplicates. For example, you can suggest a user content that’s similar to what they’re currently looking at, or label a support ticket as a duplicate if it’s very similar to an already existing one.\n",
    "\n",
    "Each Doc, Span and Token comes with a .similarity() method that lets you compare it with another object, and determine the similarity. Of course similarity is always subjective – whether “dog” and “cat” are similar really depends on how you’re looking at it. spaCy’s similarity model usually assumes a pretty general-purpose definition of similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QM55wLVeyra1",
    "outputId": "641db032-91d8-4c1b-fe7c-6cae04d2ccaa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog dog 1.0\n",
      "dog cat 0.8016855\n",
      "dog banana 0.24327648\n",
      "cat dog 0.8016855\n",
      "cat cat 1.0\n",
      "cat banana 0.28154367\n",
      "banana dog 0.24327648\n",
      "banana cat 0.28154367\n",
      "banana banana 1.0\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_md\")  # make sure to use larger model!\n",
    "tokens = nlp(\"dog cat banana\")\n",
    "\n",
    "for token1 in tokens:\n",
    "    for token2 in tokens:\n",
    "        print(token1.text, token2.text, token1.similarity(token2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PaCnvLAi6iGW"
   },
   "source": [
    "## The Vocab object\n",
    "\n",
    "spaCy tries to store the data in a vocabulary, i.e. `Vocab` that is shared by multiple documents. \n",
    "\n",
    "To save memory, spaCy also encodes all strings to hash values – in this case for example, “coffee” has the hash 3197928453018144401. Entity labels like “ORG” and part-of-speech tags like “VERB” are also encoded. Internally, spaCy only “speaks” in hash values.\n",
    "\n",
    "* **Token**: A word, punctuation mark etc. in context, including its attributes, tags and dependencies.\n",
    "* **Lexeme**: A “word type” with no context. Includes the word shape and flags, e.g. if it’s lowercase, a digit or punctuation.\n",
    "* **Doc**: A processed container of tokens in context.\n",
    "* **Vocab**: The collection of lexemes.\n",
    "* **StringStore**: The dictionary mapping hash values to strings, for example 3197928453018144401 → “coffee”.\n",
    "\n",
    "Thus: \n",
    "\n",
    "* `Vocab` objects contain a set of look-up tables that make common information available across documents.\n",
    "* Indexing the `Vocab` retrieves a `Lexeme`, which contains all the context-independent information about a word.\n",
    "\n",
    "![alt text](https://spacy.io/vocab_stringstore-1d1c9ccd7a1cf4d168bfe4ca791e6eed.svg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "Qj-5mite9mIK",
    "outputId": "6e103ca2-39a5-4f59-be0b-8f483c8e2c8d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.vocab.Vocab at 0x7f08789d4848>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "Vg-Q-_XV9sqm",
    "outputId": "59bfdc59-2db5-4929-a615-694204815ec2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lexeme.Lexeme at 0x7f085af3ecf0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc7.vocab[\"Apple\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "vjCFRsyo94G1",
    "outputId": "a7def412-7c4d-4a82-9b98-bc8794d7e6a4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lexeme.Lexeme at 0x7f085af3ef30>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lex = doc7.vocab[\"million\"]\n",
    "lex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "dixcACbB994o",
    "outputId": "ffbbb94e-10a1-461d-a66b-e27567f509fb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xxxx'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lex.shape_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "-1I3Kp_V-AzH",
    "outputId": "c65ab9d6-c5d9-49cf-c78d-16fcd1979118"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'million'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lex.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "T6gbPjeh-B_j",
    "outputId": "addbcaeb-bae4-42ce-f58c-e451840d7360"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lex.is_alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pgVUba0w6x-c"
   },
   "source": [
    "# Hands on: practical examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KQJAS9b67KIB"
   },
   "source": [
    "## Word frequency\n",
    "\n",
    "We can compute the word frequency on a text using spaCy. Within the Holy Grail dataset, lets:\n",
    "\n",
    "\n",
    "\n",
    "*   Let's find the 5 most common nouns\n",
    "*   Let's find the 20 most common lemmas that are not stopwords\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uZ3zlWUS602k",
    "outputId": "4e09592c-5352-450e-cae4-5f9605b99a4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-11-28 16:54:41--  https://raw.githubusercontent.com/vfp1/bts-dsf-2020/main/data/what_da_holy.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.192.133, 151.101.128.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 65003 (63K) [text/plain]\n",
      "Saving to: ‘what_da_holy.txt’\n",
      "\n",
      "what_da_holy.txt    100%[===================>]  63.48K  --.-KB/s    in 0.03s   \n",
      "\n",
      "2020-11-28 16:54:41 (2.01 MB/s) - ‘what_da_holy.txt’ saved [65003/65003]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget 'https://raw.githubusercontent.com/vfp1/bts-dsf-2020/main/data/what_da_holy.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q5ltWhKMGdbM"
   },
   "source": [
    "### Find the 5 most common nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "A8ETiMYyBkqo"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en\")\n",
    "\n",
    "holy_grail = nlp(open('what_da_holy.txt', 'r').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "LMsQCxazDBe-"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "char_counter = Counter()\n",
    "\n",
    "for token in holy_grail:\n",
    "    if token.pos_ == 'NOUN' and token.text not in STOP_WORDS and token.text != '#':\n",
    "        char_counter[token.text] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2ryIDsxuDONW",
    "outputId": "d2900746-5826-4343-da92-df0c597011e9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('boom', 42), ('witch', 37), ('music', 29), ('clop', 26), ('singing', 26)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_counter.most_common(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hdz3FWI9Gi79"
   },
   "source": [
    "### Find the 20 most common lemmas that are not stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "NIXHe3iCGxMx"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "lemmas = Counter()\n",
    "\n",
    "for token in holy_grail:\n",
    "    if token.pos_ != 'PROPN' and not token.is_punct and not token.is_digit and not token.is_space and token.lower_ not in STOP_WORDS:\n",
    "        lemmas[token.lemma_] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yAn8t5kKHRMB",
    "outputId": "83176ac8-3f41-4202-ab7c-d5a295a6a0b1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('oh', 110),\n",
       " ('ha', 59),\n",
       " ('right', 55),\n",
       " ('yes', 53),\n",
       " ('come', 46),\n",
       " ('boom', 42),\n",
       " ('witch', 41),\n",
       " ('clop', 39),\n",
       " ('burn', 39),\n",
       " ('away', 38),\n",
       " ('look', 37),\n",
       " ('stop', 35),\n",
       " ('uh', 33),\n",
       " ('get', 30),\n",
       " ('tell', 30),\n",
       " ('music', 29),\n",
       " ('dead', 28),\n",
       " ('run', 28),\n",
       " ('squeak', 28),\n",
       " ('go', 27)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = Counter(lemmas)\n",
    "counts.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rRRSwVjpJXxF"
   },
   "source": [
    "### Your turn\n",
    "\n",
    "* Let's find the 5 most common verbs\n",
    "* Let's find the 5 most common personal names\n",
    "* Let's find the 20 most common lemmas that are not stopwords, not numbers and not personal names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eMzD5GpipS13"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8_xXkO_b7WrG"
   },
   "source": [
    "## Dispersion plots\n",
    "\n",
    "1. Load the `holy_grail.txt` dataset and create a dictionary of names and indexes like `{\"NAME\": [1, 2, 5, 10, ...]}` to store when does each proper noun appear among the 5 most frequent ones.\n",
    "2. Visualize the appearances of the character that is named the most.\n",
    "3. Visualize in the same graph the appearances of the top 5 characters to compare them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "Jma_xH1s7YD0"
   },
   "outputs": [],
   "source": [
    "from spacy import load\n",
    "\n",
    "nlp = load(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "lY3hpd3VIIDb"
   },
   "outputs": [],
   "source": [
    "holy_grail = nlp(open(\"what_da_holy.txt\", 'r').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "lcUhtPg3KMYa"
   },
   "outputs": [],
   "source": [
    "# We are using Counter to start the tuple madness\n",
    "from collections import Counter\n",
    "\n",
    "char_counter = Counter()\n",
    "\n",
    "for token in holy_grail:\n",
    "    if token.pos_ == 'PROPN':\n",
    "        char_counter[token.text] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FQLta8KLKQhc",
    "outputId": "128cb5fa-9be3-4c84-8ca5-0702b3d64dd7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ARTHUR', 225),\n",
       " ('LAUNCELOT', 76),\n",
       " ('KNIGHT', 66),\n",
       " ('GALAHAD', 64),\n",
       " ('FATHER', 62),\n",
       " ('BEDEVERE', 58),\n",
       " ('HEAD', 54),\n",
       " ('Sir', 52),\n",
       " ('Ni', 46),\n",
       " ('ROBIN', 38)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_counter.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gZSZrhV_ML2C"
   },
   "source": [
    "We get Sir or HEAD within the characters, actually HEAD is a character, but Sir is not, let's change that using a `special case`, instead of the longer and ardous task of training.\n",
    "\n",
    "* HEAD should be HEAD KNIGHT\n",
    "* NI should be KNIGHTS OF NI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "_Mpqv-9tMeUu"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "from spacy.symbols import ORTH, POS, NOUN, VERB, TAG, PROPN\n",
    "\n",
    "nlp_modified = spacy.load('en')\n",
    "nlp_modified.tokenizer.add_special_case('Sir', [{ORTH: 'Sir', POS: NOUN, TAG: NOUN}])\n",
    "nlp_modified.tokenizer.add_special_case('HEAD', [{ORTH: 'HEAD KNIGHT', POS: PROPN, TAG: PROPN}])\n",
    "nlp_modified.tokenizer.add_special_case('KNIGHT', [{ORTH: 'HEAD KNIGHT', POS: PROPN, TAG: PROPN}])\n",
    "nlp_modified.tokenizer.add_special_case('NI', [{ORTH: 'KNIGHTS OF NI', POS: PROPN, TAG: PROPN}])\n",
    "nlp_modified.tokenizer.add_special_case('Ni', [{ORTH: 'KNIGHTS OF NI', POS: PROPN, TAG: PROPN}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SjikAIe0Mtmy"
   },
   "source": [
    "Let's try it again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "7eu6fFJRM9nB"
   },
   "outputs": [],
   "source": [
    "holy_grail2 = nlp_modified(open(\"what_da_holy.txt\", 'r').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "xCaMiq2lMxUm"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "char_counter2 = Counter()\n",
    "\n",
    "for token in holy_grail2:\n",
    "    if token.pos_ == 'PROPN':\n",
    "        char_counter2[token.text] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ERH8zzWgMzI6",
    "outputId": "78be4acd-e536-48a4-cd20-61658ef5b2f3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ARTHUR', 225),\n",
       " ('HEAD KNIGHT', 122),\n",
       " ('LAUNCELOT', 76),\n",
       " ('GALAHAD', 64),\n",
       " ('KNIGHTS OF NI', 62)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_counter2.most_common(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BDL1Cl_wRpMB"
   },
   "source": [
    "### Visualize the most"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lH8gjzkYRtOp",
    "outputId": "33cbad3c-51d5-447b-cecc-45adee496d77"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ARTHUR', 225)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_counter2.most_common(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "6Ceu5EvnKQ5-"
   },
   "outputs": [],
   "source": [
    "names, _ = zip(*char_counter2.most_common(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BBitn2kSyaxb",
    "outputId": "06bd2af2-1d26-41e0-820a-efc0b46ae30a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ARTHUR',)\n"
     ]
    }
   ],
   "source": [
    "print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "IS94mXKWPh0t"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "xAu-X9I1RHLt"
   },
   "outputs": [],
   "source": [
    "indexes = defaultdict(list)\n",
    "\n",
    "for token in holy_grail2:\n",
    "    if token.text in names:\n",
    "        indexes[token.text].append(token.i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uo2zLp-ixby-",
    "outputId": "ebb9dcd8-8f99-4265-e556-6202dfbf932a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {'ARTHUR': [13, 37, 83, 147, 162, 188, 225, 250, 271, 316, 343, 393, 454, 468, 530, 1255, 1266, 1293, 1314, 1341, 1373, 1412, 1500, 1536, 1550, 1652, 1682, 1701, 1740, 1766, 1788, 1810, 1842, 1862, 1884, 1983, 2015, 2055, 2083, 2116, 2308, 2399, 2412, 2442, 2469, 2476, 2490, 2501, 2521, 2543, 2562, 2593, 2604, 2636, 2652, 2683, 2708, 2725, 2744, 2763, 2788, 2802, 2824, 2855, 2883, 3899, 4150, 4168, 4203, 4219, 4393, 4440, 4465, 4663, 4746, 4801, 4838, 4878, 4986, 5012, 5052, 5130, 5146, 5183, 5216, 5270, 5358, 5448, 5497, 5534, 5583, 5620, 5799, 5855, 5889, 5920, 9040, 9086, 9104, 9140, 9180, 9205, 9281, 9309, 9367, 9396, 9444, 9478, 9504, 9526, 9536, 9577, 9608, 9623, 13098, 13137, 13166, 13209, 13240, 13256, 13272, 13293, 13319, 13326, 13344, 13361, 13376, 13386, 13412, 13474, 13524, 13542, 13588, 13680, 13719, 13846, 13864, 13908, 13939, 13975, 14093, 14124, 14216, 14251, 14282, 14586, 14638, 14661, 14678, 14701, 14739, 14791, 14848, 14891, 14950, 14970, 14986, 15013, 15035, 15057, 15147, 15250, 15279, 15309, 15325, 15344, 15356, 15366, 15383, 15395, 15416, 15552, 15605, 15683, 15700, 15733, 15774, 15796, 15814, 15854, 15889, 15911, 15926, 16007, 16030, 16268, 16289, 16305, 16329, 16365, 16413, 16467, 16516, 16550, 16593, 16694, 16745, 16895, 16910, 16936, 16962, 16981, 17002, 17037, 17048, 17113, 17147, 17176, 17483, 17503, 17527, 17569, 17610, 17629, 17660, 17747, 17870, 17930, 17972, 18029, 18094, 18111, 18144, 18184, 18225]})\n"
     ]
    }
   ],
   "source": [
    "print(indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "id": "Ie9U4y2uRKa2",
    "outputId": "1470423d-f242-41da-a187-3e0279dd9cde"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f08769c5e48>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots()\n",
    "\n",
    "axes.eventplot(indexes['ARTHUR'], label=names)\n",
    "axes.get_yaxis().set_visible(False)\n",
    "\n",
    "fig.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D0WqqmIiTHoY"
   },
   "source": [
    "### Visualize all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oNCam-CtTlAW",
    "outputId": "eb920d55-16e3-4a31-a827-7b6086acd0e8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ARTHUR', 225),\n",
       " ('HEAD KNIGHT', 122),\n",
       " ('LAUNCELOT', 76),\n",
       " ('GALAHAD', 64),\n",
       " ('KNIGHTS OF NI', 62)]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_counter2.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "Uv63xSimTlAb"
   },
   "outputs": [],
   "source": [
    "names, _ = zip(*char_counter2.most_common(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CwwpqGVGl5iX",
    "outputId": "a9c263c9-9b26-459a-e275-b84c6e824fe2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ARTHUR', 'HEAD KNIGHT', 'LAUNCELOT', 'GALAHAD', 'KNIGHTS OF NI') (225, 122, 76, 64, 62)\n"
     ]
    }
   ],
   "source": [
    "print(names, _)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "ekEirwPqTlAe"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B_WuRbgYTlAg",
    "outputId": "a314ffa7-5d5d-4d29-b0aa-4e4e7d18dca7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "37\n",
      "83\n",
      "147\n",
      "162\n",
      "188\n",
      "225\n",
      "250\n",
      "271\n",
      "316\n",
      "343\n",
      "393\n",
      "454\n",
      "468\n",
      "530\n",
      "1255\n",
      "1266\n",
      "1293\n",
      "1314\n",
      "1341\n",
      "1373\n",
      "1412\n",
      "1500\n",
      "1536\n",
      "1550\n",
      "1652\n",
      "1682\n",
      "1701\n",
      "1740\n",
      "1766\n",
      "1788\n",
      "1810\n",
      "1842\n",
      "1862\n",
      "1884\n",
      "1983\n",
      "2015\n",
      "2055\n",
      "2083\n",
      "2116\n",
      "2186\n",
      "2202\n",
      "2208\n",
      "2226\n",
      "2232\n",
      "2249\n",
      "2258\n",
      "2261\n",
      "2273\n",
      "2285\n",
      "2288\n",
      "2298\n",
      "2308\n",
      "2392\n",
      "2399\n",
      "2405\n",
      "2412\n",
      "2434\n",
      "2442\n",
      "2460\n",
      "2469\n",
      "2476\n",
      "2479\n",
      "2490\n",
      "2494\n",
      "2501\n",
      "2512\n",
      "2521\n",
      "2534\n",
      "2543\n",
      "2554\n",
      "2562\n",
      "2569\n",
      "2593\n",
      "2597\n",
      "2604\n",
      "2624\n",
      "2636\n",
      "2642\n",
      "2652\n",
      "2673\n",
      "2683\n",
      "2701\n",
      "2708\n",
      "2714\n",
      "2725\n",
      "2734\n",
      "2744\n",
      "2763\n",
      "2767\n",
      "2775\n",
      "2788\n",
      "2796\n",
      "2802\n",
      "2817\n",
      "2824\n",
      "2833\n",
      "2855\n",
      "2859\n",
      "2867\n",
      "2883\n",
      "2891\n",
      "3899\n",
      "4150\n",
      "4168\n",
      "4203\n",
      "4219\n",
      "4393\n",
      "4429\n",
      "4440\n",
      "4446\n",
      "4451\n",
      "4465\n",
      "4663\n",
      "4746\n",
      "4801\n",
      "4838\n",
      "4878\n",
      "4953\n",
      "4966\n",
      "4986\n",
      "5012\n",
      "5052\n",
      "5130\n",
      "5135\n",
      "5146\n",
      "5183\n",
      "5216\n",
      "5251\n",
      "5270\n",
      "5350\n",
      "5358\n",
      "5411\n",
      "5448\n",
      "5497\n",
      "5534\n",
      "5583\n",
      "5608\n",
      "5620\n",
      "5799\n",
      "5855\n",
      "5889\n",
      "5920\n",
      "6090\n",
      "6098\n",
      "6521\n",
      "6535\n",
      "6542\n",
      "6554\n",
      "6565\n",
      "6574\n",
      "6587\n",
      "6601\n",
      "6627\n",
      "6639\n",
      "6651\n",
      "6657\n",
      "6667\n",
      "6683\n",
      "6692\n",
      "6699\n",
      "6718\n",
      "6734\n",
      "6748\n",
      "6778\n",
      "6784\n",
      "6793\n",
      "6820\n",
      "6828\n",
      "7153\n",
      "7213\n",
      "7256\n",
      "7274\n",
      "7380\n",
      "7401\n",
      "7428\n",
      "7461\n",
      "7500\n",
      "7619\n",
      "7669\n",
      "7691\n",
      "7732\n",
      "7751\n",
      "7771\n",
      "7801\n",
      "7825\n",
      "7850\n",
      "7926\n",
      "7946\n",
      "7965\n",
      "8001\n",
      "8057\n",
      "8138\n",
      "8407\n",
      "8419\n",
      "8425\n",
      "8432\n",
      "8437\n",
      "8442\n",
      "8447\n",
      "8452\n",
      "8469\n",
      "8477\n",
      "8489\n",
      "8502\n",
      "8511\n",
      "8523\n",
      "8568\n",
      "8580\n",
      "8629\n",
      "8640\n",
      "8711\n",
      "8729\n",
      "8739\n",
      "8753\n",
      "8769\n",
      "8779\n",
      "8800\n",
      "8818\n",
      "8833\n",
      "8843\n",
      "8852\n",
      "9040\n",
      "9086\n",
      "9104\n",
      "9140\n",
      "9180\n",
      "9205\n",
      "9254\n",
      "9255\n",
      "9257\n",
      "9259\n",
      "9264\n",
      "9266\n",
      "9269\n",
      "9272\n",
      "9275\n",
      "9278\n",
      "9281\n",
      "9288\n",
      "9289\n",
      "9300\n",
      "9306\n",
      "9309\n",
      "9320\n",
      "9324\n",
      "9325\n",
      "9338\n",
      "9339\n",
      "9350\n",
      "9367\n",
      "9381\n",
      "9382\n",
      "9389\n",
      "9396\n",
      "9400\n",
      "9418\n",
      "9419\n",
      "9421\n",
      "9426\n",
      "9428\n",
      "9431\n",
      "9434\n",
      "9437\n",
      "9440\n",
      "9444\n",
      "9458\n",
      "9459\n",
      "9478\n",
      "9489\n",
      "9490\n",
      "9504\n",
      "9512\n",
      "9514\n",
      "9517\n",
      "9520\n",
      "9523\n",
      "9526\n",
      "9536\n",
      "9555\n",
      "9556\n",
      "9577\n",
      "9582\n",
      "9599\n",
      "9600\n",
      "9608\n",
      "9614\n",
      "9615\n",
      "9623\n",
      "9628\n",
      "9629\n",
      "11076\n",
      "11096\n",
      "11145\n",
      "11261\n",
      "11292\n",
      "11317\n",
      "11363\n",
      "11381\n",
      "11464\n",
      "11480\n",
      "11502\n",
      "11519\n",
      "11572\n",
      "11610\n",
      "11634\n",
      "11669\n",
      "11725\n",
      "11749\n",
      "11771\n",
      "11793\n",
      "11845\n",
      "11905\n",
      "11936\n",
      "11971\n",
      "12024\n",
      "12056\n",
      "12088\n",
      "12112\n",
      "12139\n",
      "12243\n",
      "12290\n",
      "12388\n",
      "12663\n",
      "12939\n",
      "12969\n",
      "13004\n",
      "13023\n",
      "13047\n",
      "13098\n",
      "13137\n",
      "13144\n",
      "13166\n",
      "13209\n",
      "13240\n",
      "13242\n",
      "13256\n",
      "13272\n",
      "13293\n",
      "13316\n",
      "13319\n",
      "13323\n",
      "13326\n",
      "13344\n",
      "13348\n",
      "13358\n",
      "13361\n",
      "13363\n",
      "13373\n",
      "13376\n",
      "13378\n",
      "13383\n",
      "13386\n",
      "13388\n",
      "13393\n",
      "13412\n",
      "13474\n",
      "13521\n",
      "13524\n",
      "13542\n",
      "13547\n",
      "13563\n",
      "13564\n",
      "13588\n",
      "13595\n",
      "13596\n",
      "13610\n",
      "13616\n",
      "13618\n",
      "13624\n",
      "13625\n",
      "13664\n",
      "13667\n",
      "13668\n",
      "13680\n",
      "13697\n",
      "13701\n",
      "13702\n",
      "13719\n",
      "13728\n",
      "13731\n",
      "13732\n",
      "13775\n",
      "13789\n",
      "13795\n",
      "13798\n",
      "13801\n",
      "13811\n",
      "13812\n",
      "13846\n",
      "13856\n",
      "13857\n",
      "13864\n",
      "13884\n",
      "13892\n",
      "13893\n",
      "13908\n",
      "13914\n",
      "13915\n",
      "13933\n",
      "13939\n",
      "13961\n",
      "13966\n",
      "13967\n",
      "13975\n",
      "13986\n",
      "13999\n",
      "14000\n",
      "14027\n",
      "14093\n",
      "14113\n",
      "14114\n",
      "14124\n",
      "14172\n",
      "14173\n",
      "14184\n",
      "14200\n",
      "14216\n",
      "14230\n",
      "14235\n",
      "14236\n",
      "14251\n",
      "14261\n",
      "14270\n",
      "14271\n",
      "14282\n",
      "14287\n",
      "14288\n",
      "14334\n",
      "14586\n",
      "14638\n",
      "14661\n",
      "14678\n",
      "14701\n",
      "14739\n",
      "14791\n",
      "14813\n",
      "14848\n",
      "14878\n",
      "14891\n",
      "14950\n",
      "14970\n",
      "14986\n",
      "14991\n",
      "15013\n",
      "15027\n",
      "15035\n",
      "15057\n",
      "15147\n",
      "15250\n",
      "15270\n",
      "15279\n",
      "15309\n",
      "15319\n",
      "15325\n",
      "15344\n",
      "15356\n",
      "15366\n",
      "15383\n",
      "15395\n",
      "15416\n",
      "15480\n",
      "15498\n",
      "15552\n",
      "15605\n",
      "15683\n",
      "15700\n",
      "15733\n",
      "15774\n",
      "15786\n",
      "15791\n",
      "15796\n",
      "15807\n",
      "15814\n",
      "15854\n",
      "15868\n",
      "15889\n",
      "15895\n",
      "15903\n",
      "15911\n",
      "15916\n",
      "15926\n",
      "16007\n",
      "16020\n",
      "16030\n",
      "16268\n",
      "16282\n",
      "16289\n",
      "16305\n",
      "16313\n",
      "16321\n",
      "16329\n",
      "16348\n",
      "16359\n",
      "16365\n",
      "16413\n",
      "16448\n",
      "16467\n",
      "16508\n",
      "16516\n",
      "16545\n",
      "16550\n",
      "16566\n",
      "16581\n",
      "16593\n",
      "16603\n",
      "16624\n",
      "16671\n",
      "16694\n",
      "16699\n",
      "16745\n",
      "16888\n",
      "16895\n",
      "16910\n",
      "16936\n",
      "16956\n",
      "16962\n",
      "16975\n",
      "16981\n",
      "17002\n",
      "17026\n",
      "17037\n",
      "17048\n",
      "17078\n",
      "17113\n",
      "17141\n",
      "17147\n",
      "17167\n",
      "17176\n",
      "17219\n",
      "17243\n",
      "17262\n",
      "17280\n",
      "17295\n",
      "17424\n",
      "17440\n",
      "17457\n",
      "17483\n",
      "17503\n",
      "17527\n",
      "17569\n",
      "17610\n",
      "17629\n",
      "17660\n",
      "17747\n",
      "17870\n",
      "17930\n",
      "17972\n",
      "18029\n",
      "18094\n",
      "18111\n",
      "18144\n",
      "18184\n",
      "18225\n"
     ]
    }
   ],
   "source": [
    "indexes = defaultdict(list)\n",
    "\n",
    "for token in holy_grail2:\n",
    "    if token.text in names:\n",
    "        print(token.i)\n",
    "        indexes[token.text].append(token.i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jLVryFL4miHO",
    "outputId": "259e42fd-5111-4d87-f2fe-935558d622f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {'ARTHUR': [13, 37, 83, 147, 162, 188, 225, 250, 271, 316, 343, 393, 454, 468, 530, 1255, 1266, 1293, 1314, 1341, 1373, 1412, 1500, 1536, 1550, 1652, 1682, 1701, 1740, 1766, 1788, 1810, 1842, 1862, 1884, 1983, 2015, 2055, 2083, 2116, 2308, 2399, 2412, 2442, 2469, 2476, 2490, 2501, 2521, 2543, 2562, 2593, 2604, 2636, 2652, 2683, 2708, 2725, 2744, 2763, 2788, 2802, 2824, 2855, 2883, 3899, 4150, 4168, 4203, 4219, 4393, 4440, 4465, 4663, 4746, 4801, 4838, 4878, 4986, 5012, 5052, 5130, 5146, 5183, 5216, 5270, 5358, 5448, 5497, 5534, 5583, 5620, 5799, 5855, 5889, 5920, 9040, 9086, 9104, 9140, 9180, 9205, 9281, 9309, 9367, 9396, 9444, 9478, 9504, 9526, 9536, 9577, 9608, 9623, 13098, 13137, 13166, 13209, 13240, 13256, 13272, 13293, 13319, 13326, 13344, 13361, 13376, 13386, 13412, 13474, 13524, 13542, 13588, 13680, 13719, 13846, 13864, 13908, 13939, 13975, 14093, 14124, 14216, 14251, 14282, 14586, 14638, 14661, 14678, 14701, 14739, 14791, 14848, 14891, 14950, 14970, 14986, 15013, 15035, 15057, 15147, 15250, 15279, 15309, 15325, 15344, 15356, 15366, 15383, 15395, 15416, 15552, 15605, 15683, 15700, 15733, 15774, 15796, 15814, 15854, 15889, 15911, 15926, 16007, 16030, 16268, 16289, 16305, 16329, 16365, 16413, 16467, 16516, 16550, 16593, 16694, 16745, 16895, 16910, 16936, 16962, 16981, 17002, 17037, 17048, 17113, 17147, 17176, 17483, 17503, 17527, 17569, 17610, 17629, 17660, 17747, 17870, 17930, 17972, 18029, 18094, 18111, 18144, 18184, 18225], 'HEAD KNIGHT': [2186, 2202, 2208, 2226, 2232, 2249, 2258, 2261, 2273, 2285, 2288, 2298, 2392, 2405, 2434, 2460, 2479, 2494, 2512, 2534, 2554, 2569, 2597, 2624, 2642, 2673, 2701, 2714, 2734, 2767, 2775, 2796, 2817, 2833, 2859, 2867, 2891, 6090, 6098, 6521, 6535, 6542, 6554, 6565, 6574, 6587, 6601, 6627, 6639, 6651, 6657, 6667, 6683, 6692, 6699, 6718, 6734, 6748, 6778, 6784, 6793, 6820, 6828, 8138, 9254, 9255, 9288, 9289, 9324, 9325, 9338, 9339, 9381, 9382, 9418, 9419, 9458, 9459, 9489, 9490, 9555, 9556, 9599, 9600, 9614, 9615, 9628, 9629, 13563, 13564, 13595, 13596, 13624, 13625, 13667, 13668, 13701, 13702, 13731, 13732, 13811, 13812, 13856, 13857, 13892, 13893, 13914, 13915, 13966, 13967, 13999, 14000, 14113, 14114, 14172, 14173, 14235, 14236, 14270, 14271, 14287, 14288], 'LAUNCELOT': [4429, 4451, 4953, 5608, 8419, 8432, 8442, 8452, 8469, 8489, 8511, 8568, 8629, 8711, 8739, 8769, 8800, 8833, 8852, 11076, 11096, 11145, 11261, 11292, 11317, 11363, 11381, 11464, 11480, 11502, 11519, 11572, 11610, 11634, 11669, 11725, 11749, 11771, 11793, 11845, 11905, 11936, 11971, 12024, 12056, 12088, 12112, 12139, 12243, 12290, 12388, 12663, 12939, 12969, 13004, 13023, 13047, 15786, 15903, 15916, 16020, 16313, 16359, 16448, 16545, 16581, 16603, 16624, 16671, 17078, 17167, 17219, 17243, 17262, 17280, 17295], 'GALAHAD': [4446, 4966, 5135, 5251, 5350, 5411, 7153, 7213, 7256, 7274, 7380, 7401, 7428, 7461, 7500, 7619, 7669, 7691, 7732, 7751, 7771, 7801, 7825, 7850, 7926, 7946, 7965, 8001, 8057, 8407, 8425, 8437, 8447, 8477, 8502, 8523, 8580, 8640, 8729, 8753, 8779, 8818, 8843, 14813, 14878, 14991, 15027, 15270, 15319, 15480, 15498, 15791, 15807, 15868, 15895, 16282, 16321, 16348, 16508, 16566, 16699, 16888, 16956, 16975, 17026, 17141, 17424, 17440, 17457], 'KNIGHTS OF NI': [9257, 9259, 9264, 9266, 9269, 9272, 9275, 9278, 9300, 9306, 9320, 9350, 9389, 9400, 9421, 9426, 9428, 9431, 9434, 9437, 9440, 9512, 9514, 9517, 9520, 9523, 9582, 13144, 13242, 13316, 13323, 13348, 13358, 13363, 13373, 13378, 13383, 13388, 13393, 13521, 13547, 13610, 13616, 13618, 13664, 13697, 13728, 13775, 13789, 13795, 13798, 13801, 13884, 13933, 13961, 13986, 14027, 14184, 14200, 14230, 14261, 14334]})\n"
     ]
    }
   ],
   "source": [
    "print(indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 403
    },
    "id": "yKL5yFmKTlAj",
    "outputId": "a1b951ab-4063-4f24-b564-f45ba6a105a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f0875aa91d0>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(5, sharex=True)\n",
    "\n",
    "for index, name in enumerate(names):\n",
    "    print(index)\n",
    "    axes[index].eventplot(indexes[name], label=name, color=\"C{}\".format(index))\n",
    "    axes[index].get_yaxis().set_visible(False)\n",
    "\n",
    "fig.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WJTnDhDzUnAx"
   },
   "source": [
    "## Your turn:\n",
    "\n",
    "* Try to plot the NOUNS and clean the Doc whenever necessary adding special cases\n",
    "\n",
    "* Try the same exercise with [this file in the GitHub repo](https://github.com/vfp1/bts-dsf-2020/blob/raw/data/pride_and_prejudice.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yi1SIWOoU81W"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "07_Text_processing.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
